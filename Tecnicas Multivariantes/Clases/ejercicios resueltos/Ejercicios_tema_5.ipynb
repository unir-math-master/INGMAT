{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicios tema 5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaRygf1O7Pgb"
      },
      "source": [
        "#Ejercicios tema 5\n",
        "\n",
        "importamos librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUsPw5ap7PAe"
      },
      "source": [
        "#!/usr/local/bin/python\n",
        "# coding: latin-1\n",
        "import os, sys\n",
        "#EJERCICIO 1\n",
        "# cargar librerias-----------------------------------------------\n",
        "import pandas as pd\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from pandas.core.common import flatten\n",
        "from plotnine import *\n",
        "from array import *\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.stats.api as sms\n",
        "# definir las rutas y caminos donde se encuentran los datos------\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "# path que se va a crear en nuestro sistema----------------------\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "# lugar de descarga del dataset----------------------------------\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHdMbo6a7VIn"
      },
      "source": [
        "# Ejercicio 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoC4SVez6_pH"
      },
      "source": [
        "\n",
        "# definir una funcion que obtenga los datos y los descargue-----\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, \n",
        "housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "fetch_housing_data()\n",
        "# definir una funcion que cargue el csv en un dataframe----------\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "housing = load_housing_data()\n",
        "# separar variable respuesta del dataset-------------------------\n",
        "respuesta = housing[\"median_house_value\"].copy()\n",
        "housing = housing.drop(\"median_house_value\", axis=1)\n",
        "# recordatorio variables numericas-------------------------------\n",
        "print(housing.info())\n",
        "# imputar NAs----------------------------------------------------\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputador = SimpleImputer(strategy=\"median\")\n",
        "# imputador.fit(housing) # da error\n",
        "# se quita la variable categorica--------------------------------\n",
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "# se calcula la imputacion---------------------------------------\n",
        "imputador.fit(housing_num)\n",
        "# los valores de las medianas------------------------------------\n",
        "print(imputador.statistics_)\n",
        "# se aplica la imputacion----------------------------------------\n",
        "housing_num_i = imputador.transform(housing_num)\n",
        "# volver a data frame--------------------------------------------\n",
        "housing_i = pd.DataFrame(housing_num_i, \n",
        "columns=housing_num.columns, index=housing.index)\n",
        "# Comprobar df imputado------------------------------------------\n",
        "print(housing_i.info())\n",
        "# importar el \"estandarizador\"-----------------------------------\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# importar la clase pipeline\"------------------------------------\n",
        "from sklearn.pipeline import Pipeline\n",
        "# definir el pipeline--------------------------------------------\n",
        "num_pipeline = Pipeline([\n",
        "        (\"imputador\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"std_scaler\", StandardScaler()),\n",
        "    ])\n",
        "\n",
        "# aplicar el pipeline--------------------------------------------\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
        "# importar clase-------------------------------------------------\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# ajustar el modelo----------------------------------------------\n",
        "lm1 = LinearRegression()\n",
        "lm1.fit(housing_num_tr, respuesta)\n",
        "# obtener coeficientes del modelo--------------------------------\n",
        "# intercepto\n",
        "print(lm1.intercept_)\n",
        "# coeficientes de regresion\n",
        "print(lm1.coef_)\n",
        "# cargar funciones-----------------------------------------------\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "# definir matriz de disenyo y variable respuesta-----------------\n",
        "X = housing_num_tr\n",
        "y = respuesta\n",
        "# anyadir intercepto---------------------------------------------\n",
        "X2 = sm.add_constant(X)\n",
        "# ajustar el modelo----------------------------------------------\n",
        "est = sm.OLS(y, X2)\n",
        "# ver ajuste-----------------------------------------------------\n",
        "est2 = est.fit()\n",
        "print(est2.summary())\n",
        "# pintar reales vs predichos\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "y_pred = lm1.predict(housing_num_tr)\n",
        "\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel(\"puntos reales\")\n",
        "plt.ylabel(\"puntos ajuste\")\n",
        "plt.plot([0, max(y)], [0, max(y)], color = 'red', linewidth = 3)\n",
        "plt.show()\n",
        "# obtener observacion medianas\n",
        "medianas = np.median(housing_num_tr, axis=0)\n",
        "print(medianas)\n",
        "# obtener observacion para predecir\n",
        "x_nueva = np.array(medianas)\n",
        "x2 = x_nueva.reshape(1, -1)\n",
        "y_nueva = lm1.predict(x2)\n",
        "print(\"el valor de y predicho es: \", y_nueva, \"dólares\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojFze8HA7XgI"
      },
      "source": [
        "# Ejercicio 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_IBY_y7JEx"
      },
      "source": [
        "#EJERCICIO2\n",
        "# Transformar variable categorica en variables indicadoras-------\n",
        "# guardar variable-----------------------------------------------\n",
        "ocean_cat = housing[[\"ocean_proximity\"]]\n",
        "# crear categorias para los encabezados--------------------------\n",
        "header_ocean_cat = housing[\"ocean_proximity\"].unique()\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "indicar_var = OneHotEncoder(sparse=False)\n",
        "ocean_indicadora = indicar_var.fit_transform(ocean_cat)\n",
        "print(ocean_indicadora)\n",
        "# volver a data frame--------------------------------------------\n",
        "ocean_df = pd.DataFrame(ocean_indicadora, \n",
        "columns = header_ocean_cat, index = housing.index)\n",
        "# Comprobar ocean_df---------------------------------------------\n",
        "print(ocean_df.info())\n",
        "print(ocean_df.head())\n",
        "# importar clase-------------------------------------------------\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# separar dataset en variables numericas y variable categorica---\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "# definir full pipeline------------------------------------------\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "# importar clase-------------------------------------------------\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# ajustar el modelo----------------------------------------------\n",
        "lm2 = LinearRegression()\n",
        "lm2.fit(housing_prepared, respuesta)\n",
        "# obtener coeficientes del modelo--------------------------------\n",
        "# intercepto\n",
        "print(lm2.intercept_)\n",
        "# coeficientes de regresion\n",
        "print(lm2.coef_)\n",
        "# importar clase-------------------------------------------------\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# separar dataset en variables numericas y variable categorica---\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "# definir full pipeline------------------------------------------\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(drop = \"first\"), cat_attribs),\n",
        "    ])\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "# importar clase-------------------------------------------------\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# ajustar el modelo----------------------------------------------\n",
        "lm2 = LinearRegression()\n",
        "lm2.fit(housing_prepared, respuesta)\n",
        "# obtener coeficientes del modelo--------------------------------\n",
        "# intercepto\n",
        "print(lm2.intercept_)\n",
        "# coeficientes de regresion\n",
        "print(lm2.coef_)\n",
        "# cargar funciones-----------------------------------------------\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "# definir matriz de disenyo y variable respuesta-----------------\n",
        "X = housing_prepared\n",
        "y = respuesta\n",
        "# anyadir intercepto---------------------------------------------\n",
        "X2 = sm.add_constant(X)\n",
        "# ajustar el modelo----------------------------------------------\n",
        "est = sm.OLS(y, X2)\n",
        "# ver ajuste-----------------------------------------------------\n",
        "est2 = est.fit()\n",
        "print(est2.summary())\n",
        "# pintar reales vs predichos\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "y_pred = lm2.predict(housing_prepared)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel(\"puntos reales\")\n",
        "plt.ylabel(\"puntos ajuste\")\n",
        "plt.plot([0, max(y)], [0, max(y)], color = 'red', linewidth = 3)\n",
        "plt.show()\n",
        "# obtener observacion medianas\n",
        "medianas = np.median(housing_num_tr, axis=0)\n",
        "print(medianas)\n",
        "# la moda de \n",
        "print(housing[\"ocean_proximity\"].value_counts())\n",
        "# obtener observacion para predecir\n",
        "array_medianas = np.array(medianas)\n",
        "x_nueva = np.append(array_medianas, [0, 0, 0, 0])\n",
        "x2 = x_nueva.reshape(1, -1)\n",
        "y_nueva = lm2.predict(x2)\n",
        "print(\"el valor de y predicho es: \", y_nueva, \"dólares.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCraMxli7Z60"
      },
      "source": [
        "# Ejercicio 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJCPvLCe7Dey"
      },
      "source": [
        "#EJERCICIO3\n",
        "# cargar funcion-------------------------------------------------\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "# predictores ejercicio 1\n",
        "housing_i.info()\n",
        "# crear dataframe para aplicar VIF\n",
        "ej1_VIF =  pd.DataFrame()\n",
        "ej1_VIF[\"variable\"] = housing_i.columns\n",
        "# aplicar el metodo\n",
        "ej1_VIF[\"VIF\"] = [variance_inflation_factor(housing_i.values, i) \n",
        "                          for i in range(len(housing_i.columns))] \n",
        "# resultados  \n",
        "print(ej1_VIF)\n",
        "# cargar funcion-------------------------------------------------\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "# predictores ejercicio 2\n",
        "housing.info()\n",
        "housing_t = pd.merge(housing_i, ocean_df, left_index = True, right_index=True)\n",
        "# es necesario quitar una de las variables categoricas-----------\n",
        "housing_t = housing_t.drop(\"<1H OCEAN\", axis=1)\n",
        "# Comprobar df creado--------------------------------------------\n",
        "print(housing_t.info())\n",
        "# crear dataframe para aplicar VIF\n",
        "ej2_VIF =  pd.DataFrame()\n",
        "ej2_VIF[\"variable\"] = housing_t.columns\n",
        "# aplicar el metodo\n",
        "ej2_VIF[\"VIF\"] = [variance_inflation_factor(housing_t.values, i)\n",
        "                          for i in range(len(housing_t.columns))]\n",
        "# resultados\n",
        "print(ej2_VIF)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}